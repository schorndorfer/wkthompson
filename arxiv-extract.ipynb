{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arXiv Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Research Idea\n",
    ":class: tip\n",
    "Identify LLM researchers, which sub-topics they are working on, and whether there is geographical specialization.\n",
    "1. Who are the researchers?\n",
    "2. Where they are located?\n",
    "3. What topics do they work on? (future work)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{card} Development Workflow\n",
    "- Identify a dataset and specify precisely what you want to do with it\n",
    "- Engineer a prompt (use OpenAI Playground)\n",
    "- Evaluate performance on a sample\n",
    "    * If performance is unacceptable, try further prompt engineering, functions, etc.\n",
    "    * If performance is still not good enough, try fine-tuning\n",
    "- Deploy at scale\n",
    "\n",
    "```{figure} ./images/gpt-dev-cycle.png\n",
    "---\n",
    "width: 500px\n",
    "name: gpt-dev-cycle\n",
    "---\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Gather Data\n",
    ":class: tip\n",
    "Promising dataset: [arXiv](https://arxiv.org/)\n",
    "- Almost all LLM papers of note are posted here\n",
    "- PDF files are freely available (~2 million covering STEM fields) \n",
    "- Limited amount of [metadata](https://www.kaggle.com/datasets/Cornell-University/arxiv/) is also available\n",
    "- Downloaded ~20K recent papers, filtered for ones containing the phrase `Large Language Model` in the abstract. Resulting dataset ~1.7K PDFs + Metadata\n",
    "- Extracted 1st page of text from each PDF\n",
    ":::\n",
    "\n",
    ":::{card} [arXiv](https://arxiv.org/)\n",
    "```{figure} ./images/arxiv.png\n",
    "---\n",
    "width: 600px\n",
    "name: arxiv\n",
    "---\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report-no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>update_date</th>\n",
       "      <th>src_pdf</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2310.00014</td>\n",
       "      <td>Yong Ren</td>\n",
       "      <td>Yong Ren, Tao Wang, Jiangyan Yi, Le Xu, Jianhu...</td>\n",
       "      <td>Fewer-token Neural Speech Codec with Time-inva...</td>\n",
       "      <td>Submitted to ICASSP 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.SD eess.AS</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>Language model based text-to-speech (TTS) mo...</td>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>2310.00014v1.pdf</td>\n",
       "      <td>FEWER-TOKEN NEURAL SPEECH CODEC WITH TIME-INVA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2310.00031</td>\n",
       "      <td>Markus Marks</td>\n",
       "      <td>Neehar Kondapaneni, Markus Marks, Manuel Knott...</td>\n",
       "      <td>Text-image Alignment for Diffusion-based Perce...</td>\n",
       "      <td>Project page: https://www.vision.caltech.edu/t...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>Diffusion models are generative models with ...</td>\n",
       "      <td>2023-10-06</td>\n",
       "      <td>2310.00031v1.pdf</td>\n",
       "      <td>Text-image Alignment for Diffusion-based Perce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2310.00032</td>\n",
       "      <td>Qinghua Xu</td>\n",
       "      <td>Qinghua Xu, Tao Yue, Shaukat Ali and Maite Arr...</td>\n",
       "      <td>Pretrain, Prompt, and Transfer: Evolving Digit...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.SE</td>\n",
       "      <td>http://creativecommons.org/licenses/by/4.0/</td>\n",
       "      <td>Cyber-Physical Systems (CPSs), e.g., elevato...</td>\n",
       "      <td>2023-10-06</td>\n",
       "      <td>2310.00032v2.pdf</td>\n",
       "      <td>PRETRAIN, PROMPT, AND TRANSFER: EVOLVING DIGIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2310.00034</td>\n",
       "      <td>Yuzhang Shang</td>\n",
       "      <td>Yuzhang Shang, Zhihang Yuan, Qiang Wu, Zhen Dong</td>\n",
       "      <td>PB-LLM: Partially Binarized Large Language Models</td>\n",
       "      <td>Frist work using network binarization for larg...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.LG cs.AI cs.CL</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>This paper explores network binarization, a ...</td>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>2310.00034v1.pdf</td>\n",
       "      <td>PB-LLM: PARTIALLY BINARIZED LARGE LANGUAGE\\nMO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2310.00035</td>\n",
       "      <td>Xi Wang</td>\n",
       "      <td>Xi Wang, Laurence Aitchison, Maja Rudolph</td>\n",
       "      <td>LoRA ensembles for large language model fine-t...</td>\n",
       "      <td>Update the title in the PDF file</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.LG cs.AI</td>\n",
       "      <td>http://creativecommons.org/licenses/by/4.0/</td>\n",
       "      <td>Finetuned LLMs often exhibit poor uncertaint...</td>\n",
       "      <td>2023-10-06</td>\n",
       "      <td>2310.00035v1.pdf</td>\n",
       "      <td>Preprint. Under review\\nENSEMBLE OF LOW-RANK A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id      submitter  \\\n",
       "0  2310.00014       Yong Ren   \n",
       "1  2310.00031   Markus Marks   \n",
       "2  2310.00032     Qinghua Xu   \n",
       "3  2310.00034  Yuzhang Shang   \n",
       "4  2310.00035        Xi Wang   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Yong Ren, Tao Wang, Jiangyan Yi, Le Xu, Jianhu...   \n",
       "1  Neehar Kondapaneni, Markus Marks, Manuel Knott...   \n",
       "2  Qinghua Xu, Tao Yue, Shaukat Ali and Maite Arr...   \n",
       "3   Yuzhang Shang, Zhihang Yuan, Qiang Wu, Zhen Dong   \n",
       "4          Xi Wang, Laurence Aitchison, Maja Rudolph   \n",
       "\n",
       "                                               title  \\\n",
       "0  Fewer-token Neural Speech Codec with Time-inva...   \n",
       "1  Text-image Alignment for Diffusion-based Perce...   \n",
       "2  Pretrain, Prompt, and Transfer: Evolving Digit...   \n",
       "3  PB-LLM: Partially Binarized Large Language Models   \n",
       "4  LoRA ensembles for large language model fine-t...   \n",
       "\n",
       "                                            comments journal-ref   doi  \\\n",
       "0                           Submitted to ICASSP 2024        None  None   \n",
       "1  Project page: https://www.vision.caltech.edu/t...        None  None   \n",
       "2                                               None        None  None   \n",
       "3  Frist work using network binarization for larg...        None  None   \n",
       "4                   Update the title in the PDF file        None  None   \n",
       "\n",
       "  report-no         categories  \\\n",
       "0      None      cs.SD eess.AS   \n",
       "1      None              cs.CV   \n",
       "2      None              cs.SE   \n",
       "3      None  cs.LG cs.AI cs.CL   \n",
       "4      None        cs.LG cs.AI   \n",
       "\n",
       "                                             license  \\\n",
       "0  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "1  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "2        http://creativecommons.org/licenses/by/4.0/   \n",
       "3  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "4        http://creativecommons.org/licenses/by/4.0/   \n",
       "\n",
       "                                            abstract update_date  \\\n",
       "0    Language model based text-to-speech (TTS) mo...  2023-10-03   \n",
       "1    Diffusion models are generative models with ...  2023-10-06   \n",
       "2    Cyber-Physical Systems (CPSs), e.g., elevato...  2023-10-06   \n",
       "3    This paper explores network binarization, a ...  2023-10-03   \n",
       "4    Finetuned LLMs often exhibit poor uncertaint...  2023-10-06   \n",
       "\n",
       "            src_pdf                                               text  \n",
       "0  2310.00014v1.pdf  FEWER-TOKEN NEURAL SPEECH CODEC WITH TIME-INVA...  \n",
       "1  2310.00031v1.pdf  Text-image Alignment for Diffusion-based Perce...  \n",
       "2  2310.00032v2.pdf  PRETRAIN, PROMPT, AND TRANSFER: EVOLVING DIGIT...  \n",
       "3  2310.00034v1.pdf  PB-LLM: PARTIALLY BINARIZED LARGE LANGUAGE\\nMO...  \n",
       "4  2310.00035v1.pdf  Preprint. Under review\\nENSEMBLE OF LOW-RANK A...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"data/arxiv_metadata.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Specify what information to extract\n",
    ":class: tip\n",
    "- title\n",
    "- list of author names\n",
    "- each author's email address\n",
    "- each author's affiliation\n",
    "- each affiliation's location in terms of latitude and longitude\n",
    ":::\n",
    "\n",
    ":::{card}\n",
    "```json\n",
    "{ \"title\": \"The paper's title\",\n",
    "    \"authors\": [\n",
    "        {\n",
    "            \"name\": \"author's name\",\n",
    "            \"email\": \"name@domain.edu\",\n",
    "            \"affiliations\": [ \"list of indices\" ]\n",
    "        }\n",
    "    ],\n",
    "    \"affiliations\": [ \n",
    "        {\"index\": \"the index\", \n",
    "        \"name\": \"The affiliation name\", \n",
    "        \"longitude\": \"the longitude\", \n",
    "        \"latitude\": \"the latitude\" \n",
    "        } \n",
    "    ]\n",
    " ]\n",
    "}\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{card}\n",
    "```{figure} ./images/arxiv-paper-header.png\n",
    "---\n",
    "width: 600px\n",
    "name: arxiv-paper-header\n",
    "---\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Develop a Prompt\n",
    ":class: tip\n",
    "[OpenAI playground](https://platform.openai.com/playground)\n",
    ":::\n",
    "\n",
    ":::{card} Prompt engineering\n",
    "There are various prompting strategies you can use to improve performance. [OpenAI](https://platform.openai.com/docs/guides/prompt-engineering/strategy-write-clear-instructions) has a very good guide to help you out. They also provide lots of examples to look at.\n",
    "\n",
    "Here are a couple of my tries:\n",
    "\n",
    "- [First attempt](https://platform.openai.com/playground/p/ZkcCdLO06jFsXm25og4Vcy5f?model=gpt-4-1106-preview&mode=chat)\n",
    "\n",
    "- [Final attempt](https://platform.openai.com/playground/p/sFEEvUESoQKSDnj6P0SVnJge?model=gpt-4-1106-preview&mode=chat)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load the .env file containing your API key\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "\n",
    "# client = OpenAI()\n",
    "\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"gpt-4-1106-preview\",\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"system\",\n",
    "#             \"content\": \"You are an expert research librarian. You are precise and can analyze the structure of papers very well. You return information in json format.\",\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": 'Extract the title and authors and affiliations from the first page of a scientific paper. \\n\\nUse the following step-by-step instructions to respond to user inputs.\\n\\nExtract the title and authors from the first page of a scientific paper. The paper text will snipped will be delimited by triple quotes. Geolocate each author affiliation with latitude and longitude.\\n\\nThe output should have the following format:\\n\\n{ \"title\": \"The paper\\'s title\",\\n  \"authors\": [\\n    {\\n      \"name\": \"Yong Ren\",\\n      \"email\": null,\\n      \"affiliations\": [ \"list of indices\" ]\\n    }\\n  ],\\n \"affiliations\": [ {\"index\": \"the index\", \"name\": \"The affiliation name\", \"longitude\": \"the longitude\", \"latitude\": \"the latitude\" } ]\\n ]\\n}\\n\\n\"\"\"\\nFEWER-TOKEN NEURAL SPEECH CODEC WITH TIME-INVARIANT CODES\\nYong Ren1,2, Tao Wang1, Jiangyan Yi1, Le Xu1,2, Jianhua Tao3, Chuyuan Zhang1,2, Junzuo Zhou1,2\\n1Institute of Automation, Chinese Academy of Sciences, China\\n2University of Chinese Academy of Sciences, China\\n3Department of Automation, Tsinghua University, China\\nABSTRACT\\nLanguage model based text-to-speech (TTS) models, like VALL-E,\\nhave gained attention for their outstanding in-context learning capa-\\nbility in zero-shot scenarios. Neural speech codec is a critical com-\\nponent of these models, which can convert speech into discrete token\\nrepresentations. However, excessive token sequences from the codec\\nmay negatively affect prediction accuracy and restrict the progres-\\nsion of Language model based TTS models. To address this issue,\\nthis paper proposes a novel neural speech codec with time-invariant\\ncodes named TiCodec. By encoding and quantizing time-invariant\\ninformation into a separate code, TiCodec can reduce the amount of\\nframe-level information that needs encoding, effectively decreasing\\nthe number of tokens as codes of speech. Furthermore, this paper\\nintroduces a time-invariant encoding consistency loss to enhance the\\nconsistency of time-invariant code within an utterance and force it\\nto capture more global information, which can benefit the zero-shot\\nTTS task. Experimental results demonstrate that TiCodec can not\\nonly enhance the quality of reconstruction speech with fewer tokens\\nbut also increase the similarity and naturalness, as well as reduce the\\nword error rate of the synthesized speech by the TTS model.\\nIndex Terms— speech codec, fewer tokens, time-invariant, lan-\\nguage model, text-to-speech\\n\"\"\"\\n ',\n",
    "#         },\n",
    "#     ],\n",
    "#     response_format={\"type\": \"json_object\"},\n",
    "#     temperature=0,\n",
    "#     max_tokens=2048,\n",
    "#     top_p=1,\n",
    "#     frequency_penalty=0,\n",
    "#     presence_penalty=0,\n",
    "#     seed=42,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# data = json.loads(response.choices[0].message.content)\n",
    "# print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "output = \"\"\"\n",
    "{\n",
    "    \"title\": \"FEWER-TOKEN NEURAL SPEECH CODEC WITH TIME-INVARIANT CODES\",\n",
    "    \"authors\": [\n",
    "        {\n",
    "            \"name\": \"Yong Ren\",\n",
    "            \"email\": null,\n",
    "            \"affiliations\": [\n",
    "                1,\n",
    "                2\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Tao Wang\",\n",
    "            \"email\": null,\n",
    "            \"affiliations\": [\n",
    "                1\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Jiangyan Yi\",\n",
    "            \"email\": null,\n",
    "            \"affiliations\": [\n",
    "                1\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Le Xu\",\n",
    "            \"email\": null,\n",
    "            \"affiliations\": [\n",
    "                1,\n",
    "                2\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Jianhua Tao\",\n",
    "            \"email\": null,\n",
    "            \"affiliations\": [\n",
    "                3\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Chuyuan Zhang\",\n",
    "            \"email\": null,\n",
    "            \"affiliations\": [\n",
    "                1,\n",
    "                2\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Junzuo Zhou\",\n",
    "            \"email\": null,\n",
    "            \"affiliations\": [\n",
    "                1,\n",
    "                2\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"affiliations\": [\n",
    "        {\n",
    "            \"index\": 1,\n",
    "            \"name\": \"Institute of Automation, Chinese Academy of Sciences, China\",\n",
    "            \"longitude\": \"116.331398\",\n",
    "            \"latitude\": \"39.897445\"\n",
    "        },\n",
    "        {\n",
    "            \"index\": 2,\n",
    "            \"name\": \"University of Chinese Academy of Sciences, China\",\n",
    "            \"longitude\": \"116.651381\",\n",
    "            \"latitude\": \"40.12114\"\n",
    "        },\n",
    "        {\n",
    "            \"index\": 3,\n",
    "            \"name\": \"Department of Automation, Tsinghua University, China\",\n",
    "            \"longitude\": \"116.326443\",\n",
    "            \"latitude\": \"40.00368\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Evaluate on a sample\n",
    ":class: tip\n",
    "To evaluate the perfomance of the GPT on your dataset, you need some way of externally validating it. At least a portion of your data must be labelled with the correct (or at least likely correct) output. This is called a `gold standard`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "user_prompt_instructions = \"\"\"\n",
    "Extract the title and authors and affiliations from the first page of a scientific paper. \n",
    "\n",
    "Use the following step-by-step instructions to respond to user inputs.\n",
    "\n",
    "Extract the title and authors from the first page of a scientific paper. The paper text will snipped will be delimited by triple quotes. Geolocate each author affiliation with latitude and longitude.\n",
    "\n",
    "The output should have the following format:\n",
    "\n",
    "{ \"title\": \"The paper's title\",\n",
    "  \"authors\": [\n",
    "    {\n",
    "      \"name\": \"Yong Ren\",\n",
    "      \"email\": null,\n",
    "      \"affiliations\": [ \"list of indices\" ]\n",
    "    }\n",
    "  ],\n",
    " \"affiliations\": [ {\"index\": \"the index\", \"name\": \"The affiliation name\", \"longitude\": \"the longitude\", \"latitude\": \"the latitude\" } ]\n",
    " ]\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import openai\n",
    "\n",
    "\n",
    "def validate_response_data(data: Dict):\n",
    "    assert \"title\" in data, \"title not found\"\n",
    "    assert \"authors\" in data, \"authors not found\"\n",
    "    for auth in data[\"authors\"]:\n",
    "        assert \"name\" in auth, \"name not found\"\n",
    "        assert \"email\" in auth, \"email not found\"\n",
    "        assert \"affiliations\" in auth, \"affiliations not found\"\n",
    "    assert \"affiliations\" in data, \"affiliations not found\"\n",
    "    for aff in data[\"affiliations\"]:\n",
    "        assert \"index\" in aff, \"index not found\"\n",
    "        assert \"name\" in aff, \"name not found\"\n",
    "        assert \"longitude\" in aff, \"longitude not found\"\n",
    "        assert \"latitude\" in aff, \"latitude not found\"\n",
    "\n",
    "\n",
    "def analyze_text(client: openai.Client, text: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert research librarian. You are precise and can analyze the structure of papers very well. You return information in json format.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt_instructions + '\\n\\n\"\"\"' + text + '\\n\\n\"\"\"',\n",
    "            },\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        seed=42,\n",
    "    )\n",
    "    try:\n",
    "        data = json.loads(response.choices[0].message.content)\n",
    "        print(data)\n",
    "        validate_response_data(data)\n",
    "        return json.dumps(data)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "client = openai.Client()\n",
    "df_sample = df.sample(100, random_state=42)\n",
    "df_sample['extracted_info'] = df_sample['text'].apply(lambda x: analyze_text(client, x))\n",
    "df_sample.to_parquet(\"sample_output.parquet\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_positives count: 3884\n",
      "false_positives count: 364\n",
      "false_negatives count: 316\n",
      "precision: 0.91\n",
      "recall: 0.92\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_gold = pd.read_parquet(\"./data/arxiv_metadata.parquet\")\n",
    "df_extracted = pd.read_parquet(\"./data/extracted_data.parquet\")\n",
    "\n",
    "true_positives = []\n",
    "false_positives = []\n",
    "false_negatives = []\n",
    "\n",
    "for id in df_extracted[\"id\"]:\n",
    "    gold_authors = list(df_gold[df_gold[\"id\"] == id][\"authors\"])[0]\n",
    "    gold_authors = {a.strip() for a in gold_authors.split(\",\")}\n",
    "\n",
    "    predicted = df_extracted[df_extracted[\"id\"] == id]\n",
    "    predicted_authors = set(predicted[\"author\"])\n",
    "\n",
    "    for author in predicted_authors:\n",
    "        if author in gold_authors:\n",
    "            true_positives.append((id, author))\n",
    "        else:\n",
    "            false_positives.append((id, author))\n",
    "\n",
    "    for author in gold_authors:\n",
    "        if author not in predicted_authors:\n",
    "            false_negatives.append((id, author))\n",
    "\n",
    "\n",
    "# round precision to 2 decimal places\n",
    "precision = round(len(true_positives) /\n",
    "                  (len(true_positives) + len(false_positives)), 2)\n",
    "\n",
    "# round recall to 2 decimal places\n",
    "recall = round(len(true_positives) /\n",
    "               (len(true_positives) + len(false_negatives)), 2)\n",
    "\n",
    "print(f\"true_positives count: {len(true_positives)}\")\n",
    "print(f\"false_positives count: {len(false_positives)}\")\n",
    "print(f\"false_negatives count: {len(false_negatives)}\")\n",
    "print(\"precision:\", precision)\n",
    "print(\"recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positives for id 2310.08102\n",
      "\n",
      "  Alham Fikri Aji\n",
      "  Muhammad Razif Rizqullah\n",
      "  Ayu Purwarianti\n",
      "\n",
      "False negatives for id 2310.08102\n",
      "\n",
      "  Ayu Purwarianti (1) and Alham Fikri Aji\n",
      "  (2) ((1) Bandung Institute of Technology\n",
      "  Muhammad Razif Rizqullah (1)\n",
      "  (2) Mohamed bin Zayed University of\n",
      "  Artificial Intelligence)\n"
     ]
    }
   ],
   "source": [
    "fp_sample = {fp[1] for fp in false_positives if fp[0] == \"2310.08102\"}\n",
    "fn_sample = {fn[1] for fn in false_negatives if fn[0] == \"2310.08102\"}\n",
    "print(f\"False positives for id 2310.08102\\n\")\n",
    "for fp in fp_sample:\n",
    "    print(f\"  {fp}\")\n",
    "\n",
    "print(f\"\\nFalse negatives for id 2310.08102\\n\")\n",
    "for fn in fn_sample:\n",
    "    print(f\"  {fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./images/arxiv-fp-fn-example.png\n",
    "---\n",
    "width: 600px\n",
    "name: arxiv-fp-fn-example\n",
    "---\n",
    "[Paper](https://arxiv.org/abs/2310.08102)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Other Forms of Evaluation\n",
    ":class: note\n",
    "Now let's map these geo-coordinates to get a sanity check on how well GPT-4 did the geo-coding. This is not a substitute for a quantitivate analysis, but it does give us more confidence if it looks reasonable\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a26e527d5a4437d9f8508b90b7459fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[42.0451, -87.6877], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'z…"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import HTML\n",
    "from ipyleaflet import Map, Marker, Popup, MarkerCluster\n",
    "\n",
    "center = (42.0451, -87.6877)\n",
    "map2 = Map(center=center, zoom=2, close_popup_on_click=True)\n",
    "\n",
    "markers = []\n",
    "for row in list(df_extracted.iterrows())[:100]:\n",
    "    marker = Marker(location=(row[1][\"latitude\"], row[1][\"longitude\"]))\n",
    "    message = HTML()\n",
    "    message.value = f\"{row[1]['author']}: <b>{row[1]['affiliation']}</b>\"\n",
    "    marker.popup = message\n",
    "    markers.append(marker)\n",
    "\n",
    "map2.add_layer(MarkerCluster(markers=markers))\n",
    "\n",
    "map2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Deploy\n",
    ":class: tip\n",
    "Deployment of this code to the full dataset requires pre-cautions:\n",
    "\n",
    "- Structure your code into source code (functions) along with unit tests\n",
    "- Functions are composed in scripts, which should have runtime tests and generate logs\n",
    "- All code (source, scripts, tests) need to be in source control, typically `git`\n",
    "- Save logs and output files in a secure location. Do not modify them.\n",
    "\n",
    "```{figure} ./images/testing.png\n",
    "---\n",
    "width: 500px\n",
    "name: testing\n",
    "---\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{card} Unit Testing\n",
    "<video width=\"99%\" height=\"600\" controls muted markdown=\"1\">\n",
    "    <source src=\"_images/unit-testing.mp4\" type=\"video/mp4\" markdown=\"1\" >\n",
    "</video>\n",
    ":::\n",
    "\n",
    ":::{card} Runtime Validation\n",
    "<video width=\"99%\" height=\"600\" controls muted markdown=\"1\">\n",
    "    <source src=\"_images/run-cli.mp4\" type=\"video/mp4\" markdown=\"1\" >\n",
    "</video>\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
